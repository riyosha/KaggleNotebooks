{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/riyosha/mushroom-binary-prediction-eda?scriptVersionId=193049157\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sns\n\nfrom sklearn.impute import SimpleImputer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/playground-series-s4e8'\ntrain = pd.read_csv(data_path+'/train.csv')\ntest = pd.read_csv(data_path+'/test.csv')\nsamplesubmission = pd.read_csv(data_path+'/sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\nprint(train.columns)\nprint('Test to Train ratio: ', test.shape[0]/train.shape[0])\nprint(train.describe(include='all'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samplesubmission.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Missing/Wrong Values","metadata":{}},{"cell_type":"code","source":"print('Rows with at least 1 missing value: ', train.isna().any(axis=1).sum())\nprint(train.isna().sum())\nprint(test.isna().sum())\n# almost all rows have at least 1 missing values, however,\n# stem-root, stem-surface, veil-type, veil-color,spore-print-color have > 50% missing values in both test and train sets. \n# we'll drop these features, assuming they are MCAR or MAR.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(columns=['stem-root','stem-surface','veil-type','veil-color','spore-print-color'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in train.columns:\n    print(col, ':', train[col].unique())\n\n# many values in the categorical columns have entries that don't make sense (numbers or phrases)\n# we'll replace them with 'missing'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n# function to deal with missing and nonsensical values\ndef clean_cats(string):\n    if pd.isna(string):\n        return 'missing'\n    elif type(string)!=str:\n        return 'missing'\n    ans=None\n    words=string.split()\n    for word in words:\n        word = re.sub(r'[^a-zA-Z]', '', word)\n        if len(word)==1:\n            ans=word\n    if ans == None or ans=='':\n        ans='missing'\n    return ans\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in train.columns:\n    if train[col].dtype==object:\n     train[col]=train[col].apply(lambda x: clean_cats(x))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Rows with at least 1 missing value: ', train.isna().any(axis=1).sum())\nprint(train.isna().sum())\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=train.dropna()\n\ntrain['id']=pd.to_numeric(train['id'])\ntrain['cap-diameter']=pd.to_numeric(train['cap-diameter'])\ntrain['stem-height']=pd.to_numeric(train['stem-height'])\ntrain['stem-width']=pd.to_numeric(train['stem-width'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I've chosen not to impute or replace missing values as my model seemed to perform marginally better when it simply used the missing category instead ","metadata":{}},{"cell_type":"markdown","source":"Finding significant features","metadata":{}},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\n\n# finds if feature is related to class\ndef significant_features(df, target='class',alpha=0.05):\n    ans={}\n    for col in df.columns:\n        if col!=target and df[col].dtype == 'object':\n            contingency_table = pd.crosstab(df[target],df[col])\n            chi2, p,_,_ = chi2_contingency(contingency_table)\n            if p<alpha:\n                ans[col] = p\n                print(f'{col} has p-value {p}')\n    return ans","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sig_features=significant_features(train)\n\nsig_features=list(sig_features.keys())+['cap-diameter','stem-width','stem-height','class']\nprocessed_train=train[sig_features]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rare Categories","metadata":{}},{"cell_type":"code","source":"# Many categories in the columns barely have any data. we'll categorise these as noise \n\nfor col in processed_train.columns:\n    if processed_train[col].dtype=='category':\n        counts = processed_train[col].value_counts().sort_values(ascending=False)\n        plt.figure(figsize=(6,3))\n        sns.barplot(x=counts.index, y=counts.values)\n        plt.title(f'{col} Frequencies')\n        plt.xlabel(col)\n        plt.ylabel('Frequency')\n        plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this will return the categories that contain 98% of the entire data. least frequent categories will be removed\ndef main_categories(df,col,threshold=0.98):\n    n = len(df[col])\n    counts=df[col].value_counts().sort_values()\n    counts =pd.DataFrame({'Category':counts.index,'Frequency':counts.values})\n    counts['Proportion']=counts['Frequency']/n\n    counts = counts.sort_values(by='Proportion', ascending=True).reset_index(drop=True)\n    counts['Cumulative_Proportion'] = counts['Proportion'].cumsum()\n    \n    return counts[counts['Proportion'] > 1-threshold]['Category'].to_list()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_categs={}\nfor col in processed_train.columns:\n    if processed_train[col].dtype=='object':\n        main_cats = main_categories(processed_train,col)+['missing']\n        main_categs[col]=main_cats\n        processed_train[col]=processed_train[col].apply(lambda x: x if x in main_cats else 'noise')\n        processed_train[col]=processed_train[col].astype('category')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in processed_train.columns:\n    print(col, ':', processed_train[col].unique())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Building the model - XGBoost (to be updated)","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report, confusion_matrix, accuracy_score,matthews_corrcoef","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = processed_train.drop(columns=['class'])\nY = processed_train['class']\nprint(X.shape,Y.shape)\n\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\nY = label_encoder.fit_transform(Y)\n\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n        'grow_policy':'depthwise',\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n        'reg_lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n        'reg_alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 10.0),\n        'enable_categorical': True\n    }\n\n    model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss')\n    model.fit(X_train, Y_train)\n    Y_pred = model.predict(X_val)\n    mcc = matthews_corrcoef(Y_val, Y_pred)\n    trial.set_user_attr(\"mcc\", mcc)\n    return mcc\n\n# Define a function for printing MCC score\ndef print_mcc_callback(study, trial):\n    mcc = trial.user_attrs[\"mcc\"]\n    print(f\"Trial {trial.number}: MCC = {mcc:.5f}, Best MCC = {study.best_value:.5f}\")\n    print(f\"Parameters: {trial.params}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''n_trials = 100\nprogress_bar = tqdm(total=n_trials)\n\n# Define a custom callback to update the progress bar\ndef progress_bar_callback(study, trial):\n    progress_bar.update(1)\n\n# Example usage: Running the optimization with 100 trials\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=n_trials, callbacks=[print_mcc_callback, progress_bar_callback])\n\n# Close the progress bar\nprogress_bar.close()\n\nbest_params = study.best_params\nprint(f\"Best parameters: {best_params}\")'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters ={'n_estimators': 432, 'max_depth': 18, 'learning_rate': 0.019177494166556952, 'subsample': 0.6944494028059239, 'colsample_bytree': 0.5177980824894136, 'gamma': 0.0004342336537981622, 'lambda': 1.3527652792856453e-06, 'alpha': 4.10797226500692e-08, 'scale_pos_weight': 1.0121323580230017,'enable_categorical': True }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is a placeholder \nparameters = {\n    'n_estimators': 100,  # Fewer trees\n    'max_depth': 5,       # Simpler model\n    'learning_rate': 0.1, \n    'subsample': 0.8,\n    'colsample_bytree': 0.8,\n    'gamma': 0.1,\n    'lambda': 1.0,\n    'alpha': 1.0,\n    'scale_pos_weight': 1.0,\n    'enable_categorical': True\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = XGBClassifier(**parameters)\nmodel = model.fit(X, Y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = model.predict(X_val)\nmcc = matthews_corrcoef(Y_val, Y_pred)\nprint(f\"Matthews Correlation Coefficient: {mcc}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now let's preprocess the test df as well\ntest['cap-diameter']=pd.to_numeric(test['cap-diameter'])\ntest['stem-height']=pd.to_numeric(test['stem-height'])\ntest['stem-width']=pd.to_numeric(test['stem-width'])\nsig_features.remove('class')\nprocessed_test=test[sig_features]\n\n\nfor col in processed_test.columns:\n    if processed_test[col].dtype==object:\n        processed_test[col]=processed_test[col].apply(lambda x: clean_cats(x))\n        main_cats=main_categs[col]\n        processed_test[col]=processed_test[col].apply(lambda x: x if x in main_cats else 'noise')\n        processed_test[col]=processed_train[col].astype('category')\n     ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id = test.pop('id')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test data\ny_test_pred = model.predict(processed_test)\ny_test_pred_binary = (y_test_pred > 0.502).astype(int)  # Convert probabilities to binary outcomes\n\n# Create the submission DataFrame\nsubmission_df = pd.DataFrame({\n    'id': id,\n    'class': y_test_pred_binary\n})\n\n# Map the binary predictions to 'e' and 'p'\nsubmission_df['class'] = np.where(submission_df['class'] == 1, 'p', 'e')\n\n# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('XGboost_model5.1_submission.csv', index=False)\nprint(\"Submission file created: submission.csv\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LightGBM Boosting","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}