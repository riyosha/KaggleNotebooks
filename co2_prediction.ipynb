{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57095,"databundleVersionId":6306871,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/riyosha/co2-prediction?scriptVersionId=191670875\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:24.083266Z","iopub.execute_input":"2024-08-08T15:33:24.0844Z","iopub.status.idle":"2024-08-08T15:33:24.097513Z","shell.execute_reply.started":"2024-08-08T15:33:24.084329Z","shell.execute_reply":"2024-08-08T15:33:24.095772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"# this notebook has picked many ideas from ambrosm's notebook on this dataset\n# https://www.kaggle.com/code/ambrosm/pss3e20-eda-which-makes-sense/notebook\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:24.278455Z","iopub.execute_input":"2024-08-08T15:33:24.278951Z","iopub.status.idle":"2024-08-08T15:33:24.285807Z","shell.execute_reply.started":"2024-08-08T15:33:24.278917Z","shell.execute_reply":"2024-08-08T15:33:24.284056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:24.337323Z","iopub.execute_input":"2024-08-08T15:33:24.338624Z","iopub.status.idle":"2024-08-08T15:33:24.34586Z","shell.execute_reply.started":"2024-08-08T15:33:24.338573Z","shell.execute_reply":"2024-08-08T15:33:24.344126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = '/kaggle/input/playground-series-s3e20'\ntrain_data = pd.read_csv(data_path+'/train.csv')\ntest_data = pd.read_csv(data_path+'/test.csv')\nsamplesubmission = pd.read_csv(data_path+'/sample_submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:24.349745Z","iopub.execute_input":"2024-08-08T15:33:24.350776Z","iopub.status.idle":"2024-08-08T15:33:26.630325Z","shell.execute_reply.started":"2024-08-08T15:33:24.350708Z","shell.execute_reply":"2024-08-08T15:33:26.62874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:26.632691Z","iopub.execute_input":"2024-08-08T15:33:26.63319Z","iopub.status.idle":"2024-08-08T15:33:26.669194Z","shell.execute_reply.started":"2024-08-08T15:33:26.633147Z","shell.execute_reply":"2024-08-08T15:33:26.667736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:26.671114Z","iopub.execute_input":"2024-08-08T15:33:26.671611Z","iopub.status.idle":"2024-08-08T15:33:26.707504Z","shell.execute_reply.started":"2024-08-08T15:33:26.671569Z","shell.execute_reply":"2024-08-08T15:33:26.705928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samplesubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:26.710773Z","iopub.execute_input":"2024-08-08T15:33:26.711231Z","iopub.status.idle":"2024-08-08T15:33:26.725167Z","shell.execute_reply.started":"2024-08-08T15:33:26.711196Z","shell.execute_reply":"2024-08-08T15:33:26.723764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape, test_data.shape, samplesubmission.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:26.727745Z","iopub.execute_input":"2024-08-08T15:33:26.728196Z","iopub.status.idle":"2024-08-08T15:33:26.740903Z","shell.execute_reply.started":"2024-08-08T15:33:26.72816Z","shell.execute_reply":"2024-08-08T15:33:26.739235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.shape[0]/train_data.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:26.74245Z","iopub.execute_input":"2024-08-08T15:33:26.74357Z","iopub.status.idle":"2024-08-08T15:33:26.758396Z","shell.execute_reply.started":"2024-08-08T15:33:26.743533Z","shell.execute_reply":"2024-08-08T15:33:26.756852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Statistical Description","metadata":{}},{"cell_type":"code","source":"'''\nWe can see that - \n1. Time range of data is from 2019 to 2021, and weekly data is provided\n2. Min and Max emmissions are 0 to 3167.768\n'''\ntrain_data.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:26.760096Z","iopub.execute_input":"2024-08-08T15:33:26.760522Z","iopub.status.idle":"2024-08-08T15:33:27.405696Z","shell.execute_reply.started":"2024-08-08T15:33:26.76044Z","shell.execute_reply":"2024-08-08T15:33:27.404129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check out the distribution of the data \nplt.figure(figsize=(5, 3))\nsns.histplot(train_data['emission'], kde=True)\nplt.title('Distribution of Emissions')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.ylim(0, 4000) \nplt.show()\n\nprint('Skew: ', train_data['emission'].skew()) # skewed to the right - we'll figure out how to handle this (if needed) while building our model","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:27.407862Z","iopub.execute_input":"2024-08-08T15:33:27.408217Z","iopub.status.idle":"2024-08-08T15:33:29.275957Z","shell.execute_reply.started":"2024-08-08T15:33:27.408187Z","shell.execute_reply":"2024-08-08T15:33:29.2743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 2))\nsns.boxplot(x=train_data['emission'])\nplt.title('Box Plot')\nplt.xlabel('Emission')\nplt.show()\n\n# most of the emissions are below 500","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:29.277918Z","iopub.execute_input":"2024-08-08T15:33:29.278443Z","iopub.status.idle":"2024-08-08T15:33:29.462672Z","shell.execute_reply.started":"2024-08-08T15:33:29.278385Z","shell.execute_reply":"2024-08-08T15:33:29.461491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing values\n\nprint('Rows with at least 1 missing value: ', train_data.isna().any(axis=1).sum())\n\n# almost all rows have some missing value, so we can't just drop the missing values. \n# We'll handle missing values EDA, before we train our model","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:29.465011Z","iopub.execute_input":"2024-08-08T15:33:29.465584Z","iopub.status.idle":"2024-08-08T15:33:29.491567Z","shell.execute_reply.started":"2024-08-08T15:33:29.465539Z","shell.execute_reply":"2024-08-08T15:33:29.489987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's find out how many geographical points we have\n\nprint(train_data.groupby(['latitude', 'longitude']).size().sort_values())\nprint(test_data.groupby(['latitude', 'longitude']).size().sort_values())\n\n# there are 497 distinct geographical points, each of which have 159 data points in training set\n# and 49 data points in the test set","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:29.493032Z","iopub.execute_input":"2024-08-08T15:33:29.493366Z","iopub.status.idle":"2024-08-08T15:33:29.517285Z","shell.execute_reply.started":"2024-08-08T15:33:29.493339Z","shell.execute_reply":"2024-08-08T15:33:29.515899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can analyse emissions according to these 497 points\npoint_mean_emissions = train_data.groupby(['latitude','longitude']).emission.mean().sort_values()\npoint_mean_emissions\n\n# alot of these points have mean 0 emissions => their prediction should likely be 0","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:29.523549Z","iopub.execute_input":"2024-08-08T15:33:29.523928Z","iopub.status.idle":"2024-08-08T15:33:29.54602Z","shell.execute_reply.started":"2024-08-08T15:33:29.523899Z","shell.execute_reply":"2024-08-08T15:33:29.544355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Geo Visualisation","metadata":{}},{"cell_type":"code","source":"# Let's visualise these points on a map \n\nimport geopandas as gpd # geosatial data visualisation\nfrom shapely.geometry import Point # representing data as a 2d or 3d point\nimport folium # for interactive maps\nimport matplotlib.colors as mcolors\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:29.54792Z","iopub.execute_input":"2024-08-08T15:33:29.548321Z","iopub.status.idle":"2024-08-08T15:33:29.555287Z","shell.execute_reply.started":"2024-08-08T15:33:29.548292Z","shell.execute_reply":"2024-08-08T15:33:29.553564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can get a heat map of these points on the geographic map \n\npoint_mean_emissions = point_mean_emissions.reset_index()\ngeometry = gpd.points_from_xy(point_mean_emissions.longitude, point_mean_emissions.latitude)\n\n# Create point geometries\ngeometry = gpd.points_from_xy(point_mean_emissions.longitude, point_mean_emissions.latitude)\ngeo_df = gpd.GeoDataFrame(\n    point_mean_emissions, geometry=geometry\n)\n\ntrain_coords_map = folium.Map(prefer_canvas=True)\n\n# Create a geometry list from the GeoDataFrame\ngeo_df_list = [[point.xy[1][0], point.xy[0][0]] for point in geo_df.geometry]\n\nnorm = plt.Normalize(vmin=np.log1p(point_mean_emissions.emission.min()), vmax=np.log1p(point_mean_emissions.emission.max()))\ncmap = plt.get_cmap('coolwarm') \n\ndef get_color(emission):\n    return mcolors.to_hex(cmap(norm(np.log1p(emission))))\ni=0\n# Iterate through list and add a marker for each emission point\nfor coordinates in geo_df_list: \n    emiss = point_mean_emissions[(point_mean_emissions['latitude']==coordinates[0]) & (point_mean_emissions['longitude']==coordinates[1])]\n    emiss = emiss['emission'].iloc[0]\n    color = get_color(emiss)\n    # Place the markers \n    train_coords_map.add_child(\n        folium.CircleMarker(\n            location=coordinates,\n            radius = 1,\n            weight = 4,\n            zoom =10,\n            fill=True,\n            popup= \n            \"Coordinates: \" + str([round(x, 2) for x in geo_df_list[i]]),\n            color = color),\n        )\n    i = i + 1\ntrain_coords_map.fit_bounds(train_coords_map.get_bounds())\ntrain_coords_map\n\n# looks like the higher emission points are more centrally located.\n# also, longitude decides the emission level much more than a point's latitude","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:29.557373Z","iopub.execute_input":"2024-08-08T15:33:29.55793Z","iopub.status.idle":"2024-08-08T15:33:31.407799Z","shell.execute_reply.started":"2024-08-08T15:33:29.557893Z","shell.execute_reply":"2024-08-08T15:33:31.405972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Timeseries EDA","metadata":{}},{"cell_type":"code","source":"#now let's analyse this data as a timeseries\n\nplt.figure(figsize=(4,2))\nsns.countplot(x='year', data=train_data)\nplt.title('Year Countplot')\nplt.show()\n\n# each year has the same number of datapoints","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:31.409722Z","iopub.execute_input":"2024-08-08T15:33:31.410232Z","iopub.status.idle":"2024-08-08T15:33:31.637188Z","shell.execute_reply.started":"2024-08-08T15:33:31.41018Z","shell.execute_reply":"2024-08-08T15:33:31.635554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,2))\nsns.countplot(x='week_no', data=train_data)\nplt.title('Week Countplot')\nplt.show()\n\nplt.figure(figsize=(10,2))\nsns.countplot(x='week_no', data=train_data[train_data['year']==2019])\nplt.title('Week Countplot (2019)')\nplt.show()\n\nplt.figure(figsize=(10,2))\nsns.countplot(x='week_no', data=train_data[train_data['year']==2020])\nplt.title('Week Countplot (2020)')\nplt.show()\n\nplt.figure(figsize=(10,2))\nsns.countplot(x='week_no', data=train_data[train_data['year']==2021])\nplt.title('Week Countplot (2021)')\nplt.show()\n\n#each week has the same amount of data points as well, and each year contains equal data for all weeks\n# datapoints are evenly spread across the weeks and years","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:31.639194Z","iopub.execute_input":"2024-08-08T15:33:31.639722Z","iopub.status.idle":"2024-08-08T15:33:33.994444Z","shell.execute_reply.started":"2024-08-08T15:33:31.639676Z","shell.execute_reply":"2024-08-08T15:33:33.992734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to analyse the entire data as a time series, we'll consider the sum of weekly emissions\ntrain_data['date'] = pd.to_datetime(train_data['year'].astype(str) + train_data['week_no'].astype(str) + '0', format='%Y%W%w')\nweekly_emissions = train_data.groupby(['date'])[['emission']].sum()\nweekly_emissions.plot(figsize=(12,2))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:33.996215Z","iopub.execute_input":"2024-08-08T15:33:33.996624Z","iopub.status.idle":"2024-08-08T15:33:34.617201Z","shell.execute_reply.started":"2024-08-08T15:33:33.996591Z","shell.execute_reply":"2024-08-08T15:33:34.615884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's look at its TSA decomposition\n\nimport statsmodels.api as sm\n\nrcParams['figure.figsize'] = (15,6)\ndecomposition = sm.tsa.seasonal_decompose(weekly_emissions, model='additive',period=52)\nfig = decomposition.plot()\nplt.show()\n\n# we see a decreasing trend in 2020, which can be attributed to COVID.\n# Near 2020 end, the emissions start rising again","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:34.619209Z","iopub.execute_input":"2024-08-08T15:33:34.619754Z","iopub.status.idle":"2024-08-08T15:33:36.835731Z","shell.execute_reply.started":"2024-08-08T15:33:34.61971Z","shell.execute_reply":"2024-08-08T15:33:36.833897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now let's plot the time series of different geo points together\n\nplt.figure(figsize=(13,4))\nfor _,point in train_data[['latitude','longitude']].drop_duplicates().iterrows():\n    ts = train_data[(train_data['latitude']==point.latitude)&(train_data['longitude']==point.longitude)].emission\n    plt.plot(range(len(ts)),ts)\n\nplt.title('Time series for every geographical point')\nfor week in [0, 53, 106, 159]:\n    plt.axvline(week, color='k', linestyle='--')\n\nplt.xlabel('Week')\nplt.ylabel('Emissions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:36.838177Z","iopub.execute_input":"2024-08-08T15:33:36.838756Z","iopub.status.idle":"2024-08-08T15:33:38.902364Z","shell.execute_reply.started":"2024-08-08T15:33:36.838711Z","shell.execute_reply":"2024-08-08T15:33:38.900873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's look at each point's trend to see if there are any anomalies\nplt.figure(figsize=(13,7))\nfor _,point in train_data[['latitude','longitude']].drop_duplicates().iterrows():\n    ts = train_data[(train_data['latitude']==point.latitude)&(train_data['longitude']==point.longitude)].emission\n    decomp = sm.tsa.seasonal_decompose(ts, model='additive',period=52)\n    plt.plot(range(len(decomp.trend)),decomp.trend)\n\nplt.title('Trend for every geographical point')\nfor week in [0, 53, 106, 159]:\n    plt.axvline(week, color='k', linestyle='--')\n\nplt.xlabel('Week')\nplt.ylabel('Emissions')\nplt.show()\n\n# all series dip at least a little in 2020 and then rise again\n# the lowest emitting geo points don't seem to be affected much","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:33:38.904866Z","iopub.execute_input":"2024-08-08T15:33:38.905312Z","iopub.status.idle":"2024-08-08T15:33:42.048149Z","shell.execute_reply.started":"2024-08-08T15:33:38.905272Z","shell.execute_reply":"2024-08-08T15:33:42.04667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature Analysis","metadata":{}},{"cell_type":"code","source":"train_data.columns","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:37:34.848835Z","iopub.execute_input":"2024-08-08T15:37:34.849391Z","iopub.status.idle":"2024-08-08T15:37:34.859215Z","shell.execute_reply.started":"2024-08-08T15:37:34.84935Z","shell.execute_reply":"2024-08-08T15:37:34.857959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can pick the most correlated features to train our model on\ntop20_corrs = abs(train_data.drop(columns=['ID_LAT_LON_YEAR_WEEK']).corr()['emission']).sort_values(ascending = False).head(21)\ntop20_corrs\n# as observed on the map earlier, latitude doesn't seem to be very correlated to a point's emission","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:38:59.337525Z","iopub.execute_input":"2024-08-08T15:38:59.338009Z","iopub.status.idle":"2024-08-08T15:39:00.548815Z","shell.execute_reply.started":"2024-08-08T15:38:59.337965Z","shell.execute_reply":"2024-08-08T15:39:00.547204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix=train_data[list(top20_corrs.keys())].corr()\nplt.figure(figsize=(15,10))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1, linewidths=0.5)\nplt.title('Correlation Matrix')\nplt.show()\n\n# we can see that some variables are highly correlated. \n# for starters, we can pick 3 features to train our model on (in addition to year and week_no)\n# the first should intuitively be longitude already\n# UvAerosolLayerHeight_aerosol_height is not correlated to longitude, so let this be the 2nd feature\n# UvAerosolLayerHeight_aerosol_pressure is almost perfectly negatively correlated to vAerosolLayerHeight_aerosol_height, so we don't get any new info and skip this feature\n# ","metadata":{"execution":{"iopub.status.busy":"2024-08-08T15:39:29.643435Z","iopub.execute_input":"2024-08-08T15:39:29.643972Z","iopub.status.idle":"2024-08-08T15:39:32.122144Z","shell.execute_reply.started":"2024-08-08T15:39:29.643936Z","shell.execute_reply":"2024-08-08T15:39:32.120626Z"},"trusted":true},"execution_count":null,"outputs":[]}]}